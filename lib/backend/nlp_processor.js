import dotenv from "dotenv";
import { createClient } from "@supabase/supabase-js";
import OpenAI from "openai";

dotenv.config();

// ğŸ—„ï¸ Connect to Supabase
const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_ANON_KEY
);

// ğŸ¤– Connect to OpenAI
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// ğŸ§  NLP Processor with batch
async function processMessages(batchSize = 10) {
  console.log("ğŸ”µ Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ NLP...");

  // 1ï¸âƒ£ Fetch raw telegram messages
  const { data: rawMessages, error } = await supabase
    .from("telegram_raw_messages")
    .select("*")
    .order("id", { ascending: true });

  if (error) {
    console.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„:", error);
    return;
  }

  if (!rawMessages || rawMessages.length === 0) {
    console.log("â„¹ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø±Ø³Ø§Ø¦Ù„ Ø¬Ø¯ÙŠØ¯Ø©.");
    return;
  }

  console.log(`ğŸ“© Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„: ${rawMessages.length}`);

  // 2ï¸âƒ£ Process messages in batches
  for (let i = 0; i < rawMessages.length; i += batchSize) {
    const batch = rawMessages.slice(i, i + batchSize);
    console.log(`â³ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯ÙØ¹Ø© Ù…Ù† ${i + 1} Ø¥Ù„Ù‰ ${i + batch.length}`);

    for (const msg of batch) {
      try {
        const prompt = `
Ø­Ù„Ù‘Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ø§Ù„Ø®Ø§ØµØ© Ø¨ÙˆØ¶Ø¹ Ø§Ù„Ø·Ø±Ù‚ ÙÙŠ ÙÙ„Ø³Ø·ÙŠÙ†.
Ø£Ø±Ø¬Ø¹ ÙÙ‚Ø· JSON Ø¨Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„ØªØ§Ù„ÙŠ:

{
  "status": "",
  "location": "",
  "confidence": 0,
  "reasoning": "",
  "detected_terms": []
}

Ø§Ù„Ù†Øµ:
"""${msg.message}"""
`;

        const completion = await openai.chat.completions.create({
          model: "gpt-3.5-turbo", // ÙŠÙ…ÙƒÙ† ØªØºÙŠÙŠØ±Ù‡ Ù„Ù€ gpt-4o-mini
          messages: [{ role: "user", content: prompt }],
          temperature: 0.2,
        });

        const aiResponse = completion.choices[0].message.content;
        console.log("ğŸ§¾ Ø§Ù„Ù†Ø§ØªØ¬:", aiResponse);

        // Parse JSON
        let result;
        try {
          result = JSON.parse(aiResponse);
        } catch {
          console.error("âš ï¸ JSON ØºÙŠØ± ØµØ§Ù„Ø­! ØªØ®Ø·ÙŠ Ø§Ù„Ø±Ø³Ø§Ù„Ø©.");
          continue;
        }

        // Save to processed table
        const { error: saveError } = await supabase
          .from("telegram_processed_messages")
          .insert({
            raw_id: msg.id,
            message: msg.message,
            status: result.status,
            location: result.location,
            confidence: result.confidence,
            reasoning: result.reasoning,
            detected_terms: result.detected_terms,
          });

        if (saveError) {
          console.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„:", saveError);
        } else {
          console.log(`âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© ${msg.id} Ø¨Ù†Ø¬Ø§Ø­.`);
        }
      } catch (err) {
        console.error("âš ï¸ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø³Ø§Ù„Ø©:", err);
      }
    }

    // 3ï¸âƒ£ Ø§Ù†ØªØ¸Ø± 1.5 Ø«Ø§Ù†ÙŠØ© Ø¨ÙŠÙ† ÙƒÙ„ Ø¯ÙØ¹Ø©
    await new Promise((res) => setTimeout(res, 1500));
  }

  console.log("ğŸ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„.");
}

// ğŸš€ Run
processMessages();
